{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Feature Extraction, Word Segmentation, bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:8\n",
      "Word Segmentation:{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumps': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction - CountVectorizer\n",
    "\n",
    "# import tools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# fit data\n",
    "en = ['The quick brown fox jumps over a lazy dog']\n",
    "vect.fit(en)\n",
    "\n",
    "print('Words:{}'.format(len(vect.vocabulary_)))\n",
    "# 'a' is ignored\n",
    "print('Word Segmentation:{}'.format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Chinese: pip install jieba\n",
    "# skip for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform to bag of words:<1x8 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# define bag of words model\n",
    "bag_of_words = vect.transform(en)\n",
    "print('transform to bag of words:{}'.format(repr(bag_of_words)))\n",
    "\n",
    "# we get a matrix with 1 row and 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words Density:[[1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# density of words in bag of words\n",
    "print('Words Density:{}'.format(bag_of_words.toarray()))\n",
    "\n",
    "# the: 1 time; quick:1; brown: 0; fox: 2; jumps: 3; over: 5; lazy: 4; dog: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words Density:[[1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# optimize the bag of words model - n_Gram\n",
    "joke = ['Mary bought this book from Candy as a gift to James']\n",
    "vect.fit(joke)\n",
    "joke_feature = vect.transform(joke)\n",
    "print('Words Density:{}'.format(joke_feature.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words Density:[[1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# change the order of the words in the sentence\n",
    "joke2 = ['James bought this book from Mary as a gift to Candy']\n",
    "vect.fit(joke2)\n",
    "joke2_feature = vect.transform(joke2)\n",
    "print('Words Density:{}'.format(joke2_feature.toarray()))\n",
    "\n",
    "# same array for different meanings - a problem of bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new dictionary:['as gift', 'book from', 'bought this', 'candy as', 'from candy', 'gift to', 'mary bought', 'this book', 'to james']\n",
      "new words density:[[1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# use parameter ngram_range to slove the problem\n",
    "# n = 2 bigram, mean checking 2 close words; n = 3 trigram\n",
    "vect = CountVectorizer(ngram_range = (2,2))\n",
    "cv = vect.fit(joke)\n",
    "joke_feature = cv.transform(joke)\n",
    "\n",
    "# print new dictionary\n",
    "print('new dictionary:{}'.format(cv.get_feature_names()))\n",
    "print('new words density:{}'.format(joke_feature.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as gift', 'book from', 'bought this', 'from mary', 'gift to', 'james bought', 'mary as', 'this book', 'to candy']\n",
      "[[1 1 1 0 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "joke2_feature = vect.transform(joke2)\n",
    "cv2 = vect.fit(joke2)\n",
    "print(format(cv2.get_feature_names()))\n",
    "print(format(joke2_feature.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users/cherry/Desktop/aclImdb [error opening dir]\r\n",
      "\r\n",
      "0 directories, 0 files\r\n"
     ]
    }
   ]
